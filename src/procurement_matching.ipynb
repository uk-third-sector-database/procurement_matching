{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40b9a21a-d87e-4b36-bb95-bded398a852f",
   "metadata": {},
   "source": [
    "## Section 0\n",
    "\n",
    "\n",
    "### Section 0.1\n",
    "\n",
    "First, lets load the libraries we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e073d25-0026-42d2-a1cd-cd51d9623e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import html\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from matching_helpers import normaliser,\\\n",
    "                             parse_datetime,\\\n",
    "                             read_raw_data,\\\n",
    "                             prepare_nhsspend,\\\n",
    "                             prepare_contractsfinder,\\\n",
    "                             org_counter,\\\n",
    "                             strip_html,\\\n",
    "                             unique_agg,\\\n",
    "                             process_dates,\\\n",
    "                             make_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcbd42c-0d0e-4d8b-a5c5-1dedec05901e",
   "metadata": {},
   "source": [
    "### Section 0.2\n",
    "\n",
    "Lets load the raw payments data we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bc4ed12-36c8-42cb-9997-01c771fe7739",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "df_centgov = read_raw_data('centgov_data.csv', 'Contracts Finder')\n",
    "df_nhs = read_raw_data('nhsspend_data.csv', 'NHSSpend')\n",
    "df_contracts = read_raw_data('contractsfinder_data.csv', 'Contracts Finder')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bbf6e2-3eb6-49ae-9440-150f9eb6995d",
   "metadata": {},
   "source": [
    "### Section 0.3\n",
    "\n",
    "Wrangle them a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f18ecd37-3d4c-4cd9-9bd1-e617813f1aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_centgov = df_centgov[['data_source', 'amount', 'supplier', 'date', 'dept']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b677e21-64c7-40d4-bc6e-bfc1d8f8ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nhs = prepare_nhsspend(df_nhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "283132ef-7ae8-49ec-81e4-7caac2dddc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contracts = prepare_contractsfinder(df_contracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6883471-6698-46ca-962c-c82b5d01dc66",
   "metadata": {},
   "source": [
    "### Section 0.4\n",
    "\n",
    "Merge and clean them a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73613a77-8eb9-4497-b570-b7780dfc0501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 926 rows of data because of numeric suppliers\n",
      "Dropping 0 rows of data because of NaN suppliers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90a90cce68a4aa88aa0b1c87c5926cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9331286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDropping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_comb[df_comb[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSUPPLIER\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows of data because of NaN suppliers\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m df_comb \u001b[38;5;241m=\u001b[39m df_comb[df_comb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUPPLIER\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotnull()]\n\u001b[1;32m---> 13\u001b[0m df_comb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUPPLIER\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_comb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUPPLIER\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mprogress_apply(strip_html)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDropping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_comb[df_comb[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSUPPLIER\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows of data after html parsing\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m df_comb \u001b[38;5;241m=\u001b[39m df_comb[df_comb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUPPLIER\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotnull()]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:917\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[1;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(df, df_function)(wrapper, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4639\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4640\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4755\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4758\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4759\u001b[0m         func,\n\u001b[0;32m   4760\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4761\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4762\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4763\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4764\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1290\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1291\u001b[0m )\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:912\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[0;32m    911\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Dropbox\\charity_data\\procurement_matching\\github\\procurement_matching\\src\\matching_helpers.py:67\u001b[0m, in \u001b[0;36mstrip_html\u001b[1;34m(html)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstrip_html\u001b[39m(html):\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m---> 67\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     68\u001b[0m         soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m soup\u001b[38;5;241m.\u001b[39mget_text()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\warnings.py:179\u001b[0m, in \u001b[0;36msimplefilter\u001b[1;34m(action, category, lineno, append)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malways\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    176\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monce\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid action: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (action,)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(lineno, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m lineno \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \\\n\u001b[0;32m    178\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlineno must be an int >= 0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 179\u001b[0m _add_filter(action, \u001b[38;5;28;01mNone\u001b[39;00m, category, \u001b[38;5;28;01mNone\u001b[39;00m, lineno, append\u001b[38;5;241m=\u001b[39mappend)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\warnings.py:193\u001b[0m, in \u001b[0;36m_add_filter\u001b[1;34m(append, *item)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m filters:\n\u001b[0;32m    192\u001b[0m         filters\u001b[38;5;241m.\u001b[39mappend(item)\n\u001b[1;32m--> 193\u001b[0m _filters_mutated()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_comb = pd.concat([df_nhs, df_centgov, df_contracts], ignore_index=True)\n",
    "df_comb = df_comb.rename({'supplier': 'SUPPLIER'}, axis=1)\n",
    "df_comb['SUPPLIER'] = df_comb['SUPPLIER'].str.upper().str.strip()\n",
    "\n",
    "df_comb['SUPPLIER_NUMERIC'] = pd.to_numeric(df_comb['SUPPLIER'], errors='coerce')\n",
    "print(f'Dropping {len(df_comb[df_comb[\"SUPPLIER\"].isnull()])} rows of data because of numeric suppliers')\n",
    "df_comb = df_comb[df_comb['SUPPLIER'].notnull()]\n",
    "df_comb = df_comb[df_comb['SUPPLIER_NUMERIC'].isna()]\n",
    "df_comb = df_comb.drop(columns='SUPPLIER_NUMERIC')\n",
    "\n",
    "print(f'Dropping {len(df_comb[df_comb[\"SUPPLIER\"].isnull()])} rows of data because of NaN suppliers')\n",
    "df_comb = df_comb[df_comb['SUPPLIER'].notnull()]\n",
    "df_comb['SUPPLIER'] = df_comb['SUPPLIER'].progress_apply(strip_html)\n",
    "print(f'Dropping {len(df_comb[df_comb[\"SUPPLIER\"].isnull()])} rows of data after html parsing')\n",
    "df_comb = df_comb[df_comb['SUPPLIER'].notnull()]\n",
    "df_comb['date'] = df_comb['date'].astype(str).str.split('T').str[0]\n",
    "df_comb['date'] = pd.to_datetime(df_comb['date'],\n",
    "                                 format='mixed',\n",
    "                                 errors='coerce')\n",
    "df_comb['date'] = df_comb['date'].map(lambda x: x.strftime('%d-%m-%Y') if pd.notnull(x) else np.nan)\n",
    "print(f'Dropping {len(df_comb[df_comb[\"date\"].isnull()])} rows of data due to NaN dates')\n",
    "df_comb = df_comb[df_comb['date'].notnull()]\n",
    "print(f'Dropping {len(df_comb[df_comb[\"amount\"].isnull()])} rows of data due to NaN amounts')\n",
    "df_comb = df_comb[df_comb['amount'].notnull()]\n",
    "print(f'Dropping {len(df_comb[df_comb[\"dept\"].isnull()])} rows of data due to NaN depts')\n",
    "df_comb = df_comb[df_comb['dept'].notnull()]\n",
    "df_comb['NORMALIZED_SUPPLIER'] = df_comb['SUPPLIER'].progress_apply(normaliser)\n",
    "df_comb = df_comb[df_comb['NORMALIZED_SUPPLIER'].apply(isinstance, args=(str,))]\n",
    "\n",
    "rows_to_drop = len(df_comb[\n",
    "    (df_comb[\"SUPPLIER\"].str.len() <= 3) |\n",
    "    (df_comb[\"NORMALIZED_SUPPLIER\"].str.len() <= 3)\n",
    "])\n",
    "\n",
    "# Print the message with the count of rows to be dropped\n",
    "print(f'Dropping {rows_to_drop} rows of data due to supplier str len<=3')\n",
    "\n",
    "df_comb = df_comb[\n",
    "    (df_comb[\"SUPPLIER\"].str.len() > 3) |\n",
    "    (df_comb[\"NORMALIZED_SUPPLIER\"].str.len() > 3)\n",
    "]\n",
    "\n",
    "df_comb[['SUPPLIER', 'ORG_COUNT']] = df_comb['SUPPLIER'].apply(lambda x: pd.Series(org_counter(x)))\n",
    "all_rows = len(df_comb)\n",
    "\n",
    "for supplier in [\"SUCCESSFUL SUPPL\",\n",
    "                 \"SEE ATTACH\",\n",
    "                 \"REFER ATTACH\",\n",
    "                 \"CONTRACT WAS AWARD\",\n",
    "                 \"AWARDED SUPPLIERS\",\n",
    "                 \"SUCCESSFUL SUPPLIER\",\n",
    "                 \"PLEASE SEE\",\n",
    "                 'NAMED IND',\n",
    "                 'REDACT',\n",
    "                 \"PLEASE REFER\"]:\n",
    "    df_comb = df_comb[~df_comb['SUPPLIER'].str.contains(supplier)]\n",
    "\n",
    "print(f'Number of rows dropped due to redacted: {len(df_comb)-all_rows}')\n",
    "\n",
    "print(f'Dropping {len(df_comb[df_comb[\"ORG_COUNT\"]!=1])} where org_count !=1')\n",
    "df_comb = df_comb[df_comb['ORG_COUNT']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f635202d-2a1f-4d87-9264-0e28dce79f10",
   "metadata": {},
   "source": [
    "### Section 0.5\n",
    "\n",
    "Merge them into a unique dataframe, and then process it (inc. normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f5ac99-8d9b-4acf-bde7-8a3f5b8029f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniq = df_comb.pivot_table(index=['SUPPLIER'],\n",
    "                              values=['date',\n",
    "                                      'contractsfinder_region',\n",
    "                                      'contractsfinder_awardedToVcse',\n",
    "                                      'dept'],\n",
    "                              aggfunc=unique_agg).reset_index()\n",
    "df_sum = df_comb.groupby('SUPPLIER')['amount'].sum().reset_index()\n",
    "df_counts = df_comb['SUPPLIER'].value_counts().reset_index()\n",
    "df_uniq = pd.merge(df_uniq,\n",
    "                   df_sum,\n",
    "                   how='left',\n",
    "                   left_on='SUPPLIER',\n",
    "                   right_on='SUPPLIER'\n",
    "                  )\n",
    "df_uniq[['SUPPLIER', 'ORG_COUNT']] = df_uniq['SUPPLIER'].progress_apply(lambda x: pd.Series(org_counter(x)))\n",
    "df_uniq['NORMALIZED_SUPPLIER'] = df_uniq['SUPPLIER'].progress_apply(normaliser)\n",
    "df_uniq = df_uniq[df_uniq['NORMALIZED_SUPPLIER'].apply(isinstance, args=(str,))]\n",
    "df_uniq = pd.merge(df_uniq,\n",
    "                   df_counts,\n",
    "                   how='left',\n",
    "                   left_on='SUPPLIER',\n",
    "                   right_on='SUPPLIER'\n",
    "                  )\n",
    "df_uniq.sort_values(by=['amount'],\n",
    "                    ascending=False)\n",
    "\n",
    "df_uniq1 = df_nhs[['supplier',\n",
    "                   'NHSSpend_CompanyName',\n",
    "                   'NHSSpend_CompanyNumber',\n",
    "                   'NHSSpend_CharityName',\n",
    "                   'NHSSpend_CharityRegNo',\n",
    "                   'NHSSpend_CharitySubNo',\n",
    "                   'NHSSpend_CharityNameNo',\n",
    "                   'NHSSpend_CharityName']].drop_duplicates()\n",
    "df_uniq = pd.merge(df_uniq,\n",
    "                   df_uniq1,\n",
    "                   how='left',\n",
    "                   left_on='SUPPLIER',\n",
    "                   right_on='supplier'\n",
    "                  )\n",
    "\n",
    "\n",
    "contractsfinder_region = df_sum = df_comb.groupby('SUPPLIER')['amount'].sum().reset_index()\n",
    "\n",
    "\n",
    "df_uniq = df_uniq.rename({'count': 'PAYMENT_TOTAL_COUNT',\n",
    "                          'amount': 'PAYMENT_TOTAL_AMOUNT'},\n",
    "                         axis=1)\n",
    "print(f'Dropping {len(df_uniq[df_uniq[\"ORG_COUNT\"]!=1])} org_count !=1')\n",
    "df_uniq = df_uniq[df_uniq['ORG_COUNT']==1]\n",
    "df_uniq = df_uniq.drop(columns='supplier')\n",
    "df_uniq['contractsfinder_awardedToVcse'] = df_uniq['contractsfinder_awardedToVcse'].apply(lambda x: \"True\" if True in x else \"False\")\n",
    "df_uniq['deptcount'] = df_uniq['dept'].apply(len)\n",
    "df_uniq['contractsfinder_region'] = df_uniq['contractsfinder_region'].apply(lambda x: \"\" if x == [np.nan] else x)\n",
    "df_uniq['date'] = df_uniq['date'].astype(str).progress_apply(process_dates)\n",
    "df_uniq['SUPPLIER'] = df_uniq['SUPPLIER'].replace('\"', \"[DQ]\", regex=True)\n",
    "df_uniq['dept'] = df_uniq['dept'].replace('\"', \"[DQ]\", regex=True)\n",
    "df_comb['SUPPLIER'] = df_comb['SUPPLIER'].replace('\"', \"[DQ]\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c05492-95b4-40ef-9bc4-412672228bea",
   "metadata": {},
   "source": [
    "### Section 0.6\n",
    "\n",
    "Drop stuff that isn't any longer needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdabed9-fe97-4c5f-9e92-c9162f45f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniq = df_uniq.drop('NHSSpend_CharityNameNo', axis=1)\n",
    "df_uniq = df_uniq.drop('NHSSpend_CharityName', axis=1)\n",
    "df_uniq = df_uniq.drop('NHSSpend_CompanyName', axis=1)\n",
    "\n",
    "df_comb = df_comb.drop('NHSSpend_CharityNameNo', axis=1)\n",
    "df_comb = df_comb.drop('NHSSpend_CharityName', axis=1)\n",
    "df_comb = df_comb.drop('NHSSpend_CompanyName', axis=1)\n",
    "df_comb = df_comb.drop('NHSSpend_audit_type', axis=1)\n",
    "df_comb = df_comb.drop('NHSSpend_CHnotes', axis=1)\n",
    "df_comb = df_comb.drop('NHSSpend_CCnotes', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324ad8ad-66f1-43c9-9155-d689ac44fcc1",
   "metadata": {},
   "source": [
    "### Section 0.7\n",
    "\n",
    "See what's left in our dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a64f178-2c1c-40df-8995-b01a7a5b0826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SUPPLIER', 'contractsfinder_awardedToVcse', 'contractsfinder_region',\n",
      "       'date', 'dept', 'PAYMENT_TOTAL_AMOUNT', 'ORG_COUNT',\n",
      "       'NORMALIZED_SUPPLIER', 'PAYMENT_TOTAL_COUNT', 'NHSSpend_CompanyNumber',\n",
      "       'NHSSpend_CharityRegNo', 'NHSSpend_CharitySubNo', 'deptcount'],\n",
      "      dtype='object')\n",
      "                                 SUPPLIER contractsfinder_awardedToVcse  \\\n",
      "0             \u0003\u0004\u0005\u0006\u0002\u0007KPMG ADVISORY LIMITED                         False   \n",
      "1                  [DQ] INVESTIGO LTD[DQ]                         False   \n",
      "2   [DQ] PRICEWATERHOUSECOOPERS (PWC)[DQ]                         False   \n",
      "3                    [DQ] SOFTCAT LTD[DQ]                         False   \n",
      "4  [DQ] TRANSOFT SOLUTIONS UK LIMITED[DQ]                         False   \n",
      "\n",
      "                              contractsfinder_region        date  \\\n",
      "0                                       [Any region]  20-07-2018   \n",
      "1  [North East,North West,Yorkshire and The Humbe...  08-04-2022   \n",
      "2  [North East,North West,Yorkshire and The Humbe...  23-09-2022   \n",
      "3  [North East,North West,Yorkshire and The Humbe...  04-03-2022   \n",
      "4  [North East,North West,Yorkshire and The Humbe...  31-03-2022   \n",
      "\n",
      "                                         dept  PAYMENT_TOTAL_AMOUNT  \\\n",
      "0  [DEPARTMENT FOR INTERNATIONAL DEVELOPMENT]             1164891.0   \n",
      "1                 [NATIONAL HIGHWAYS LIMITED]              106250.0   \n",
      "2                 [NATIONAL HIGHWAYS LIMITED]              460001.5   \n",
      "3                 [NATIONAL HIGHWAYS LIMITED]              220085.0   \n",
      "4                 [NATIONAL HIGHWAYS LIMITED]              413694.0   \n",
      "\n",
      "   ORG_COUNT            NORMALIZED_SUPPLIER  PAYMENT_TOTAL_COUNT  \\\n",
      "0          1              KPMG ADVISORY LTD                    1   \n",
      "1          1                  INVESTIGO LTD                    1   \n",
      "2          1     PRICEWATERHOUSECOOPERS PWC                    1   \n",
      "3          1                    SOFTCAT LTD                    1   \n",
      "4          1  TRANSOFT SOLUTIONS UK LIMITED                    1   \n",
      "\n",
      "  NHSSpend_CompanyNumber  NHSSpend_CharityRegNo  NHSSpend_CharitySubNo  \\\n",
      "0                    NaN                    NaN                    NaN   \n",
      "1                    NaN                    NaN                    NaN   \n",
      "2                    NaN                    NaN                    NaN   \n",
      "3                    NaN                    NaN                    NaN   \n",
      "4                    NaN                    NaN                    NaN   \n",
      "\n",
      "   deptcount  \n",
      "0          1  \n",
      "1          1  \n",
      "2          1  \n",
      "3          1  \n",
      "4          1  \n"
     ]
    }
   ],
   "source": [
    "print(df_uniq.columns)\n",
    "print(df_uniq.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77023526-ecc9-4670-8f66-fccc14694f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['data_source', 'amount', 'SUPPLIER', 'date', 'dept',\n",
      "       'NHSSpend_CompanyNumber', 'NHSSpend_CharityRegNo',\n",
      "       'NHSSpend_CharitySubNo', 'NHSSpend_isCIC',\n",
      "       'contractsfinder_awardedToVcse', 'contractsfinder_region',\n",
      "       'NORMALIZED_SUPPLIER', 'ORG_COUNT'],\n",
      "      dtype='object')\n",
      "  data_source    amount                                       SUPPLIER  \\\n",
      "0    NHSSpend   69366.0                     BMI HEALTHCARE COLLECTIONS   \n",
      "1    NHSSpend   43854.0                 NORTH YORKSHIRE COUNTY COUNCIL   \n",
      "2    NHSSpend   32278.0                           NOTTINGHAM REHAB LTD   \n",
      "3    NHSSpend   48127.0             LEEDS TEACHING HOSPITALS NHS TRUST   \n",
      "4    NHSSpend  215687.0  HARROGATE & DISTRICT NHS FOUNDATION NHS TRUST   \n",
      "\n",
      "         date          dept NHSSpend_CompanyNumber  NHSSpend_CharityRegNo  \\\n",
      "0  30-09-2017  NHS_HRAW_CCG               02164270                    NaN   \n",
      "1  30-09-2017  NHS_HRAW_CCG                    NaN                    NaN   \n",
      "2  30-09-2017  NHS_HRAW_CCG               01948041                    NaN   \n",
      "3  30-09-2017  NHS_HRAW_CCG                    NaN                    NaN   \n",
      "4  30-09-2017  NHS_HRAW_CCG                    NaN                    NaN   \n",
      "\n",
      "   NHSSpend_CharitySubNo NHSSpend_isCIC contractsfinder_awardedToVcse  \\\n",
      "0                    NaN            NaN                           NaN   \n",
      "1                    NaN            NaN                           NaN   \n",
      "2                    NaN            NaN                           NaN   \n",
      "3                    NaN            NaN                           NaN   \n",
      "4                    NaN            NaN                           NaN   \n",
      "\n",
      "  contractsfinder_region                          NORMALIZED_SUPPLIER  \\\n",
      "0                    NaN                   BMI HEALTHCARE COLLECTIONS   \n",
      "1                    NaN                   NORTH YORKS COUNTY COUNCIL   \n",
      "2                    NaN                         NOTTINGHAM REHAB LTD   \n",
      "3                    NaN           LEEDS TEACHING HOSPITALS NHS TRUST   \n",
      "4                    NaN  HARROGATE DISTRICT NHS FOUNDATION NHS TRUST   \n",
      "\n",
      "   ORG_COUNT  \n",
      "0          1  \n",
      "1          1  \n",
      "2          1  \n",
      "3          1  \n",
      "4          1  \n"
     ]
    }
   ],
   "source": [
    "print(df_comb.columns)\n",
    "print(df_comb.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2981d68e-9265-4775-b1a0-7cbf764d0745",
   "metadata": {},
   "source": [
    "### Section 0.8\n",
    "\n",
    "Sort, coerce, save uniq out before normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe67b913-79ff-4507-8e9e-f3f5ceda3e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniq = df_uniq.sort_values(by='PAYMENT_TOTAL_AMOUNT',\n",
    "                              ascending=False)\n",
    "print(len(df_uniq))\n",
    "df_uniq = df_uniq.copy()[df_uniq['NORMALIZED_SUPPLIER'].notnull()]\n",
    "print(len(df_uniq))\n",
    "df_uniq = df_uniq[df_uniq['SUPPLIER'].notnull()]\n",
    "df_uniq.to_csv(os.path.join(os.getcwd(),\n",
    "                            '..',\n",
    "                            'raw_data',\n",
    "                            'merged_groupby_raw.csv'),\n",
    "               index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ea287c-16eb-43b5-b515-2d8a3aaba02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb.to_csv(os.path.join(os.getcwd(),\n",
    "                            '..',\n",
    "                            'raw_data',\n",
    "                            'merged_all_raw.csv'),\n",
    "               index=False\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cddafb-3538-4a83-a103-e6683e96255e",
   "metadata": {},
   "source": [
    "# Section 1.0 \n",
    "\n",
    "Lets now process the other auxillery registers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eda406f-4f6d-470e-872a-48ebf5d933ee",
   "metadata": {},
   "source": [
    "### Section 1.1\n",
    "\n",
    "Lets load the uniq file back in so that we can split up the cleaning and matching process if we want to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f89f1d-c4b6-4e15-ba83-194db61763ce",
   "metadata": {},
   "source": [
    "### Section 1.1\n",
    "\n",
    "CH first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd4af239-d625-41b6-9ada-1a350700e65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the most recent CH file is  5621958\n",
      "The length of part 1 of the older CH file is  849999\n",
      "The length of part 2 of the older CH file is  850000\n",
      "The length of part 3 of the older CH file is  850000\n",
      "The length of part 4 of the older CH file is  445775\n",
      "The length of the merged CH file is  7324319\n"
     ]
    }
   ],
   "source": [
    "df_ch = pd.read_csv(os.path.join(\n",
    "    '..', 'registers', 'BasicCompanyDataAsOneFile-2024-08-01.csv'),\n",
    "                    usecols=['CompanyName', ' CompanyNumber', 'RegAddress.PostTown', 'RegAddress.PostCode']\n",
    "                )\n",
    "print('The length of the most recent CH file is ', len(df_ch))\n",
    "\n",
    "df_ch_old_1 = pd.read_csv(os.path.join(\n",
    "    '..', 'registers', 'BasicCompanyData-2012-07-01-part1_4.csv'),\n",
    "                          usecols=['CompanyName', ' CompanyNumber', 'RegAddress.PostTown', 'RegAddress.PostCode']\n",
    "                         )\n",
    "print('The length of part 1 of the older CH file is ', len(df_ch_old_1))\n",
    "\n",
    "df_ch_old_2 = pd.read_csv(os.path.join(\n",
    "    '..', 'registers', 'BasicCompanyData-2012-07-01-part2_4.csv'),\n",
    "                          usecols=['CompanyName', ' CompanyNumber', 'RegAddress.PostTown', 'RegAddress.PostCode']\n",
    "                         )\n",
    "print('The length of part 2 of the older CH file is ', len(df_ch_old_2))\n",
    "\n",
    "df_ch_old_3 = pd.read_csv(os.path.join(\n",
    "    '..', 'registers', 'BasicCompanyData-2012-07-01-part3_4.csv'),\n",
    "                          usecols=['CompanyName', ' CompanyNumber', 'RegAddress.PostTown', 'RegAddress.PostCode']\n",
    "                         )\n",
    "print('The length of part 3 of the older CH file is ', len(df_ch_old_3))\n",
    "\n",
    "df_ch_old_4 = pd.read_csv(os.path.join(\n",
    "    '..', 'registers', 'BasicCompanyData-2012-07-01-part4_4.csv'),\n",
    "                          usecols=['CompanyName', ' CompanyNumber', 'RegAddress.PostTown', 'RegAddress.PostCode']\n",
    "                         )\n",
    "print('The length of part 4 of the older CH file is ', len(df_ch_old_4))\n",
    "\n",
    "df_ch = pd.concat([df_ch,df_ch_old_1], axis=0, ignore_index=True)\n",
    "df_ch = pd.concat([df_ch,df_ch_old_2], axis=0, ignore_index=True)\n",
    "df_ch = pd.concat([df_ch,df_ch_old_3], axis=0, ignore_index=True)\n",
    "df_ch = pd.concat([df_ch,df_ch_old_4], axis=0, ignore_index=True)\n",
    "\n",
    "df_ch = df_ch.drop_duplicates(subset=[' CompanyNumber'])\n",
    "print('The length of the merged CH file is ', len(df_ch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "797d47a6-4fe4-40df-8698-27d815a24096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2acb5a2644b4c6fb2ff40407aca1d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7324319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ch['NORMALIZED_CompanyName'] = df_ch['CompanyName'].astype(str).progress_apply(normaliser)\n",
    "df_ch = df_ch[df_ch['NORMALIZED_CompanyName'].apply(isinstance, args=(str,))]\n",
    "\n",
    "df_ch = df_ch[df_ch['NORMALIZED_CompanyName'].notnull()]\n",
    "df_ch = df_ch.drop_duplicates(subset=['NORMALIZED_CompanyName'], keep=False)\n",
    "df_ch = df_ch[[' CompanyNumber', 'NORMALIZED_CompanyName', 'CompanyName', 'RegAddress.PostTown', 'RegAddress.PostCode']]\n",
    "df_ch['CompanyName'] = df_ch['CompanyName'].replace('\"', \"[DQ]\", regex=True)\n",
    "df_ch.to_csv(os.path.join('..', 'registers', 'ch_w_normalised.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ee32f9-f4b2-405c-8904-11eb11ca4ea5",
   "metadata": {},
   "source": [
    "### Section 1.2\n",
    "\n",
    "Now the spine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aee86c0e-29a5-4b9c-be10-f48c3e1314b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc489e26e2b4354bbb4229436077656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/777409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_spine = pd.read_csv(os.path.join(\n",
    "    '..', 'registers', 'public_spine.spine.csv'),\n",
    "                       usecols=['uid', 'organisationname', 'fulladdress', 'city', 'postcode', 'registerdate', 'removeddate'],\n",
    "                       low_memory=False,\n",
    "                )\n",
    "df_spine['NORMALIZED_organisationname'] = df_spine['organisationname'].astype(str).progress_apply(normaliser)\n",
    "df_spine = df_spine[df_spine['NORMALIZED_organisationname'].apply(isinstance, args=(str,))]\n",
    "df_spine = df_spine[df_spine['NORMALIZED_organisationname'].notnull()]\n",
    "df_spine = df_spine.drop_duplicates(subset=['NORMALIZED_organisationname'], keep=False)\n",
    "df_spine = df_spine[['uid', 'NORMALIZED_organisationname', 'organisationname', 'fulladdress', 'city', 'postcode', 'registerdate', 'removeddate']]\n",
    "df_spine['organisationname'] = df_spine['organisationname'].replace('\"', \"[DQ]\", regex=True)\n",
    "df_spine['fulladdress'] = df_spine['fulladdress'].replace('\"', \"[DQ]\", regex=True)\n",
    "df_spine.to_csv(os.path.join('..', 'registers', 'spine_w_normalised.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a051256f-40fd-4093-993b-06bf954cd38d",
   "metadata": {},
   "source": [
    "### Section 1.3\n",
    "\n",
    "Now the NHSSpend NHS register:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "068f167a-cf03-4ab6-9929-c8fc03892a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3103e577de84e698d5ba4be375dcf24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45739 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_nhsdigital = pd.read_csv(os.path.join(\n",
    "    '..', 'registers', 'nhs_uniq.csv')\n",
    "                      )\n",
    "df_nhsdigital['NORMALIZED_NHSDigital_Supplier'] = df_nhsdigital['NHSDigital_Supplier'].astype(str).progress_apply(normaliser)\n",
    "df_nhsdigital = df_nhsdigital[df_nhsdigital['NORMALIZED_NHSDigital_Supplier'].apply(isinstance, args=(str,))]\n",
    "\n",
    "df_nhsdigital = df_nhsdigital[df_nhsdigital['NORMALIZED_NHSDigital_Supplier'].notnull()]\n",
    "df_nhsdigital = df_nhsdigital.drop_duplicates(subset=['NORMALIZED_NHSDigital_Supplier'], keep=False)\n",
    "df_nhsdigital = df_nhsdigital[['NHSDigital_Supplier', 'NORMALIZED_NHSDigital_Supplier']]\n",
    "df_nhsdigital['NHSDigital_Supplier'] = df_nhsdigital['NHSDigital_Supplier'].replace('\"', \"[DQ]\", regex=True)\n",
    "df_nhsdigital.to_csv(os.path.join('..', 'registers', 'nhsdigital_w_normalised.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751aa86c-5d7b-486e-8b4c-629c6bde6241",
   "metadata": {},
   "source": [
    "# Section 2\n",
    "\n",
    "### Section 2.1\n",
    "\n",
    "Lets now load the files back in for the matching process.\n",
    "\n",
    "#### Section 2.1.1\n",
    "\n",
    "First, the uniq suppliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fa4efc8-735d-4556-8a34-70768b801a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213632\n",
      "213631\n",
      "We are then left with 213631 rows of unique \"single\" suppliers\n"
     ]
    }
   ],
   "source": [
    "df_uniq = pd.read_csv(os.path.join(os.getcwd(),\n",
    "                                   '..',\n",
    "                                   'raw_data',\n",
    "                                   'merged_groupby_raw.csv')\n",
    "                     )\n",
    "print(len(df_uniq))\n",
    "df_uniq = df_uniq[df_uniq['NORMALIZED_SUPPLIER'].notnull()]\n",
    "print(len(df_uniq))\n",
    "print(f'We are then left with {len(df_uniq)} rows of unique \"single\" suppliers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bcf634-7355-490c-bacc-2b734f027fa4",
   "metadata": {},
   "source": [
    "#### Section 2.1.2 \n",
    "\n",
    "Then, the spine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f6e1709-2ca6-4525-88dd-b345644b3a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spine = pd.read_csv(os.path.join('..', 'registers', 'spine_w_normalised.csv'), low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50a3666-6489-4002-b6df-18ed3e89dafe",
   "metadata": {},
   "source": [
    "#### Section 2.1.3\n",
    "\n",
    "Then, the CH:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b160b97-449b-457d-9296-325e63df60ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch = pd.read_csv(os.path.join('..', 'registers', 'ch_w_normalised.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2262f89b-2dc4-4558-974e-7edca0ab9f93",
   "metadata": {},
   "source": [
    "#### Section 2.1.4\n",
    "\n",
    "Then, the NHS Digital:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73ebd7d7-cf93-4107-87b0-a8b8873d12e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nhsdigital = pd.read_csv(os.path.join('..', 'registers', 'nhsdigital_w_normalised.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937b0603-51cc-487f-bca2-0581d352d134",
   "metadata": {},
   "source": [
    "# Section 3\n",
    "\n",
    "Do the matches here.\n",
    "    \n",
    "#### Section 3.1.\n",
    "\n",
    "Make the spine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ebdc84c-354d-4bbd-b7b4-c4b14acc725a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>NORMALIZED_organisationname</th>\n",
       "      <th>organisationname</th>\n",
       "      <th>fulladdress</th>\n",
       "      <th>city</th>\n",
       "      <th>postcode</th>\n",
       "      <th>registerdate</th>\n",
       "      <th>removeddate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GB-CHC-200001</td>\n",
       "      <td>PAINTERSCOMPANY CHARITY</td>\n",
       "      <td>PAINTERS' COMPANY CHARITY</td>\n",
       "      <td>PAINTERS' HALL, 9 LITTLE TRINITY LANE, LONDON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EC4V 2AD</td>\n",
       "      <td>08/06/1961</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GB-CHC-200003</td>\n",
       "      <td>HERGA WORLD DISTRESS FUND</td>\n",
       "      <td>HERGA WORLD DISTRESS FUND</td>\n",
       "      <td>5 HIGH STREET, HARROW ON THE HILL, MIDDLESEX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HA1 3HP</td>\n",
       "      <td>08/06/1961</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GB-CHC-200004</td>\n",
       "      <td>WILLIAM GOLDSTEIN LAY STAFF BENEVOLENT FUND RO...</td>\n",
       "      <td>THE WILLIAM GOLDSTEIN LAY STAFF BENEVOLENT FUN...</td>\n",
       "      <td>THE SPECIAL TRUSTEES OFFICE, 57B WEST SMITHFIE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EC1A 9DS</td>\n",
       "      <td>08/06/1961</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GB-CHC-200007</td>\n",
       "      <td>HOLDENHURST OLD PEOPLES HOME TRUST</td>\n",
       "      <td>THE HOLDENHURST OLD PEOPLE'S HOME TRUST</td>\n",
       "      <td>BOUGH FARM, BURWASH WEALD, EAST SUSSEX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TN19 7LX</td>\n",
       "      <td>07/06/1967</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GB-CHC-200009</td>\n",
       "      <td>RALPH LEVY CHARITABLE COMPANY LTD</td>\n",
       "      <td>THE RALPH LEVY CHARITABLE COMPANY LIMITED</td>\n",
       "      <td>5-6 DOWN STREET, LONDON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W1J 7AH</td>\n",
       "      <td>17/03/1961</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676316</th>\n",
       "      <td>GB-CHC-1163677</td>\n",
       "      <td>DARUL TACLIM WAL IFTA</td>\n",
       "      <td>DARUL TACLIM WAL IFTA</td>\n",
       "      <td>106 HIGH ROAD, WILLESDEN, LONDON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NW10 2PP</td>\n",
       "      <td>21/09/2015</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676317</th>\n",
       "      <td>GB-CHC-1179370</td>\n",
       "      <td>SAFE RESCUE LTD</td>\n",
       "      <td>SAFE RESCUE LTD</td>\n",
       "      <td>11 LINCOLN AVENUE, HINGHAM, NORWICH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NR9 4NA</td>\n",
       "      <td>27/07/2018</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676318</th>\n",
       "      <td>GB-COOP-R019720</td>\n",
       "      <td>WESTONSUPERMARE EDUCATION TRUST</td>\n",
       "      <td>Weston-super-Mare Education Trust</td>\n",
       "      <td>OLDMIXON PRIMARY SCHOOL,MONKTON AVENUE</td>\n",
       "      <td>WESTON-SUPER-MARE</td>\n",
       "      <td>BS24 9DA</td>\n",
       "      <td>20/08/2013</td>\n",
       "      <td>2018-06-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676319</th>\n",
       "      <td>GB-CHC-1185102</td>\n",
       "      <td>REFUGEE RIGHTS EUROPE LTD</td>\n",
       "      <td>REFUGEE RIGHTS EUROPE LTD</td>\n",
       "      <td>71-75 SHELTON STREET, COVENT GARDEN, LONDON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WC2H 9JQ</td>\n",
       "      <td>29/08/2019</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676320</th>\n",
       "      <td>GB-CHC-1182369</td>\n",
       "      <td>SHAH E HAMDAN TRUST</td>\n",
       "      <td>SHAH E HAMDAN TRUST</td>\n",
       "      <td>17 POND HEAD LANE, EARLEY, READING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RG6 7ET</td>\n",
       "      <td>07/03/2019</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>572199 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    uid                        NORMALIZED_organisationname  \\\n",
       "1         GB-CHC-200001                            PAINTERSCOMPANY CHARITY   \n",
       "2         GB-CHC-200003                          HERGA WORLD DISTRESS FUND   \n",
       "3         GB-CHC-200004  WILLIAM GOLDSTEIN LAY STAFF BENEVOLENT FUND RO...   \n",
       "6         GB-CHC-200007                 HOLDENHURST OLD PEOPLES HOME TRUST   \n",
       "8         GB-CHC-200009                  RALPH LEVY CHARITABLE COMPANY LTD   \n",
       "...                 ...                                                ...   \n",
       "676316   GB-CHC-1163677                              DARUL TACLIM WAL IFTA   \n",
       "676317   GB-CHC-1179370                                    SAFE RESCUE LTD   \n",
       "676318  GB-COOP-R019720                    WESTONSUPERMARE EDUCATION TRUST   \n",
       "676319   GB-CHC-1185102                          REFUGEE RIGHTS EUROPE LTD   \n",
       "676320   GB-CHC-1182369                                SHAH E HAMDAN TRUST   \n",
       "\n",
       "                                         organisationname  \\\n",
       "1                               PAINTERS' COMPANY CHARITY   \n",
       "2                               HERGA WORLD DISTRESS FUND   \n",
       "3       THE WILLIAM GOLDSTEIN LAY STAFF BENEVOLENT FUN...   \n",
       "6                 THE HOLDENHURST OLD PEOPLE'S HOME TRUST   \n",
       "8               THE RALPH LEVY CHARITABLE COMPANY LIMITED   \n",
       "...                                                   ...   \n",
       "676316                              DARUL TACLIM WAL IFTA   \n",
       "676317                                    SAFE RESCUE LTD   \n",
       "676318                  Weston-super-Mare Education Trust   \n",
       "676319                          REFUGEE RIGHTS EUROPE LTD   \n",
       "676320                                SHAH E HAMDAN TRUST   \n",
       "\n",
       "                                              fulladdress               city  \\\n",
       "1           PAINTERS' HALL, 9 LITTLE TRINITY LANE, LONDON                NaN   \n",
       "2            5 HIGH STREET, HARROW ON THE HILL, MIDDLESEX                NaN   \n",
       "3       THE SPECIAL TRUSTEES OFFICE, 57B WEST SMITHFIE...                NaN   \n",
       "6                  BOUGH FARM, BURWASH WEALD, EAST SUSSEX                NaN   \n",
       "8                                 5-6 DOWN STREET, LONDON                NaN   \n",
       "...                                                   ...                ...   \n",
       "676316                   106 HIGH ROAD, WILLESDEN, LONDON                NaN   \n",
       "676317                11 LINCOLN AVENUE, HINGHAM, NORWICH                NaN   \n",
       "676318             OLDMIXON PRIMARY SCHOOL,MONKTON AVENUE  WESTON-SUPER-MARE   \n",
       "676319        71-75 SHELTON STREET, COVENT GARDEN, LONDON                NaN   \n",
       "676320                 17 POND HEAD LANE, EARLEY, READING                NaN   \n",
       "\n",
       "        postcode registerdate removeddate  \n",
       "1       EC4V 2AD   08/06/1961         NaT  \n",
       "2        HA1 3HP   08/06/1961         NaT  \n",
       "3       EC1A 9DS   08/06/1961         NaT  \n",
       "6       TN19 7LX   07/06/1967         NaT  \n",
       "8        W1J 7AH   17/03/1961         NaT  \n",
       "...          ...          ...         ...  \n",
       "676316  NW10 2PP   21/09/2015         NaT  \n",
       "676317   NR9 4NA   27/07/2018         NaT  \n",
       "676318  BS24 9DA   20/08/2013  2018-06-19  \n",
       "676319  WC2H 9JQ   29/08/2019         NaT  \n",
       "676320   RG6 7ET   07/03/2019         NaT  \n",
       "\n",
       "[572199 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spine\n",
    "\n",
    "df_spine['removeddate'] = pd.to_datetime(df_spine['removeddate'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# Filter based on the condition\n",
    "df_spine[~(df_spine['removeddate'] <= '2010-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7644451e-11a7-4044-934a-e8f347c8a6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a7d7c25cf54fc59f5343fe8212655c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/213631 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_spine_results = make_matches(df_uniq['NORMALIZED_SUPPLIER'],\n",
    "                                df_spine['NORMALIZED_organisationname'],\n",
    "                                'spine')\n",
    "df_spine_results.to_csv(os.path.join('..', 'matches', 'matches_to_spine.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2eefc3-f88b-4537-a1bc-26e322db4163",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spine_results = make_matches(df_uniq['NORMALIZED_SUPPLIER'],\n",
    "                                df_spine[~(df_spine['removeddate'] <= '2010-01-01')]['NORMALIZED_organisationname'],\n",
    "                                'spine_notclosed2010')\n",
    "df_spine_results.to_csv(os.path.join('..', 'matches', 'matches_to_spine_notclosed2010.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec852ac2-c2b2-4779-b0ca-68fc7013756e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4c0871901244d2a6fb2152275ebbf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/213631 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_spine_results = make_matches(df_uniq['NORMALIZED_SUPPLIER'],\n",
    "                                df_spine[(df_spine['removeddate'] <= '2010-01-01')]['NORMALIZED_organisationname'],\n",
    "                                'spine_closed2010')\n",
    "df_spine_results.to_csv(os.path.join('..', 'matches', 'matches_to_spine_closed2010.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60d65e4c-81f7-404a-af98-6f1967fe21ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: NORMALIZED_SUPPLIER, dtype: object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uniq['NORMALIZED_SUPPLIER'][~df_uniq['NORMALIZED_SUPPLIER'].apply(isinstance, args=(str,))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7cd0b4-29a7-4568-9b1b-085f8d950849",
   "metadata": {},
   "source": [
    "#### Section 3.2.\n",
    "\n",
    "Make the CH results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86d6ff19-4ea6-4893-835d-bb3fa9f07fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2532a95abc4a3b83ebcda7744913c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/213631 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ch_results = make_matches(df_uniq['NORMALIZED_SUPPLIER'],\n",
    "                             df_ch['NORMALIZED_CompanyName'],\n",
    "                             'ch')\n",
    "df_ch_results.to_csv(os.path.join('..', 'matches', 'matches_to_ch.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd2536d-f295-4562-999c-893f7b8e0e4d",
   "metadata": {},
   "source": [
    "#### Section 3.3.\n",
    "\n",
    "Make the NHS Digital results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d878290-bc42-41ce-b223-1788d2c74623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69de717659084bc1be7f4e34c06200a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/213631 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_nhsdigital_results = make_matches(df_uniq['NORMALIZED_SUPPLIER'], df_nhsdigital['NORMALIZED_NHSDigital_Supplier'], 'nhsdigital')\n",
    "df_nhsdigital_results.to_csv(os.path.join('..', 'matches', 'matches_to_nhsdigital.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a444a7ff-97f8-4f15-9ec4-8257da994d8c",
   "metadata": {},
   "source": [
    "# Section 4\n",
    "\n",
    "Now, merge the matches back onto the unique.\n",
    "\n",
    "### Section 4.1.\n",
    "\n",
    "First, load the matches in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45303f72-248c-45b8-bb1c-bc4080c6bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spine_results = pd.read_csv(os.path.join('..', 'matches', 'matches_to_spine.csv'), index_col=0)\n",
    "df_spine_results_notclosed2010 = pd.read_csv(os.path.join('..', 'matches', 'matches_to_spine_notclosed2010.csv'), index_col=0)\n",
    "df_spine_results_closed2010 = pd.read_csv(os.path.join('..', 'matches', 'matches_to_spine_closed2010.csv.csv'), index_col=0)\n",
    "df_ch_results = pd.read_csv(os.path.join('..', 'matches', 'matches_to_ch.csv'), index_col=0)\n",
    "df_nhsdigital_results = pd.read_csv(os.path.join('..', 'matches', 'matches_to_nhsdigital.csv'), index_col=0)\n",
    "df_uniq = pd.read_csv(os.path.join(os.getcwd(),\n",
    "                                   '..',\n",
    "                                   'raw_data',\n",
    "                                   'merged_groupby_raw.csv')\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ff837e-8a30-4706-89bd-6e1bee9e28b7",
   "metadata": {},
   "source": [
    "### Section 4.2.\n",
    "\n",
    "Add new empty fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fd34bc-dfbb-40fa-968e-0e6df4ecd46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniq['verified_normalized_spine_name'] = np.nan\n",
    "df_uniq['verified_spine_uid'] = np.nan\n",
    "df_uniq['verified_normalized_ch_name'] = np.nan\n",
    "df_uniq['verified_ch_uid'] = np.nan\n",
    "df_uniq['verified_nhsdigital_name'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877df7f2-e833-4582-94a3-601d573eea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniq = df_uniq.join(df_spine_results, how='left')\n",
    "df_uniq = df_uniq.join(df_spine_results_notclosed2010, how='left')\n",
    "df_uniq = df_uniq.join(df_spine_results_closed2010, how='left')\n",
    "df_uniq.to_csv(os.path.join(os.getcwd(),\n",
    "                            '..',\n",
    "                            'raw_data',\n",
    "                            'merged_groupby_with_approximate_spine.csv'),\n",
    "               index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c59205-cacf-447c-938e-62e8b0da6803",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniq = df_uniq.join(df_ch_results, how='left')\n",
    "df_uniq.to_csv(os.path.join(os.getcwd(),\n",
    "                            '..',\n",
    "                            'raw_data',\n",
    "                            'merged_groupby_with_approximate_spine_and_ch.csv'),\n",
    "               index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f1eee-294e-49e1-b7de-2626df2cc33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniq = df_uniq.join(df_nhsdigital_results, how='left')\n",
    "df_uniq.to_csv(os.path.join(os.getcwd(),\n",
    "                            '..',\n",
    "                            'raw_data',\n",
    "                            'merged_groupby_with_approximate_spine_and_ch_and_nhsdigital.csv'),\n",
    "               index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8c1cc5-3b32-4b4c-8d0d-d351419d134f",
   "metadata": {},
   "source": [
    "# Section 4\n",
    "\n",
    "Do some EDA here which checks that the matches have been linked back in appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77412ba4-97d6-4009-9d77-e24c23337cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniq = pd.read_csv(os.path.join(os.getcwd(),\n",
    "                                   '..',\n",
    "                                   'raw_data',\n",
    "                                   'merged_groupby_with_approximate_spine_and_ch_and_nhsdigital_old.csv'),\n",
    "                      index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddb3333-8c24-4d29-9705-6102ab262011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniq.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef6cb38-92ac-4a3a-aa51-238ea7e957ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix strange indexing bug\n",
    "df1 = df_uniq[['SUPPLIER', 'contractsfinder_awardedToVcse', 'contractsfinder_region',\n",
    "               'date', 'dept', 'PAYMENT_TOTAL_AMOUNT', 'ORG_COUNT',\n",
    "               'NORMALIZED_SUPPLIER', 'PAYMENT_TOTAL_COUNT', 'NHSSpend_CompanyNumber',\n",
    "               'NHSSpend_CharityRegNo', 'NHSSpend_CharitySubNo', 'deptcount',\n",
    "               'verified_normalized_spine_name', 'verified_spine_uid',\n",
    "               'verified_normalized_ch_name', 'verified_ch_uid',\n",
    "               'verified_nhsdigital_name']]\n",
    "df1 = df1[df1['NORMALIZED_SUPPLIER'].notnull()]\n",
    "\n",
    "df2 = df_uniq[['best_spine_match_1',\n",
    "               'best_spine_match_1_score', 'best_spine_match_2',\n",
    "               'best_spine_match_2_score', 'best_spine_match_3',\n",
    "               'best_spine_match_3_score', 'best_spine_match_4',\n",
    "               'best_spine_match_4_score', 'best_spine_match_5',\n",
    "               'best_spine_match_5_score', 'best_ch_match_1', 'best_ch_match_1_score',\n",
    "               'best_ch_match_2', 'best_ch_match_2_score', 'best_ch_match_3',\n",
    "               'best_ch_match_3_score', 'best_ch_match_4', 'best_ch_match_4_score',\n",
    "               'best_ch_match_5', 'best_ch_match_5_score', 'best_nhsdigital_match_1',\n",
    "               'best_nhsdigital_match_1_score', 'best_nhsdigital_match_2',\n",
    "               'best_nhsdigital_match_2_score', 'best_nhsdigital_match_3',\n",
    "               'best_nhsdigital_match_3_score', 'best_nhsdigital_match_4',\n",
    "               'best_nhsdigital_match_4_score', 'best_nhsdigital_match_5',\n",
    "               'best_nhsdigital_match_5_score']]\n",
    "df2 = df2[df2['best_spine_match_1_score'].notnull()]\n",
    "df1.reset_index(drop=True, inplace=True)\n",
    "df2.reset_index(drop=True, inplace=True)\n",
    "df_uniq = pd.concat([df1.copy(), df2.copy()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa38e3dd-1922-4bcd-bbe6-0a733325444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spine_w_norm = pd.read_csv(os.path.join('..', 'registers', 'spine_w_normalised.csv'), index_col=None, low_memory=False)\n",
    "df_spine_w_norm_names = df_spine_w_norm[['NORMALIZED_organisationname', 'organisationname']].drop_duplicates(subset=['NORMALIZED_organisationname'])\n",
    "for match in ['1', '2', '3', '4', '5']:\n",
    "    df_uniq = pd.merge(df_uniq, df_spine_w_norm_names, how='left', left_on='best_spine_match_' + str(match), right_on='NORMALIZED_organisationname')\n",
    "    df_uniq = df_uniq.rename({'organisationname': 'best_spine_match_' + str(match) + '_notnormalised'}, axis=1)\n",
    "    df_uniq = df_uniq.drop({'NORMALIZED_organisationname'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e3618-df0d-4ef8-ad07-8ea5818ce2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_w_norm = pd.read_csv(os.path.join('..', 'registers', 'ch_w_normalised.csv'), index_col=None, low_memory=False)\n",
    "df_ch_w_norm_names = df_ch_w_norm[['CompanyName', 'NORMALIZED_CompanyName']].drop_duplicates(subset=['NORMALIZED_CompanyName'])\n",
    "for match in ['1', '2', '3', '4', '5']:\n",
    "    df_uniq = pd.merge(df_uniq, df_ch_w_norm_names, how='left', left_on='best_ch_match_' + str(match), right_on='NORMALIZED_CompanyName')\n",
    "    df_uniq = df_uniq.rename({'CompanyName': 'best_ch_match_' + str(match) + '_notnormalised'}, axis=1)\n",
    "    df_uniq = df_uniq.drop({'NORMALIZED_CompanyName'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d78a9-913f-48ad-ba55-1e27952b4f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nhsdigital_w_norm = pd.read_csv(os.path.join('..', 'registers', 'nhsdigital_w_normalised.csv'), index_col=None, low_memory=False)\n",
    "df_nhsdigital_w_norm_names = df_nhsdigital_w_norm[['NHSDigital_Supplier', 'NORMALIZED_NHSDigital_Supplier']].drop_duplicates(subset=['NORMALIZED_NHSDigital_Supplier'])\n",
    "for match in ['1', '2', '3', '4', '5']:\n",
    "    df_uniq = pd.merge(df_uniq, df_nhsdigital_w_norm_names, how='left', left_on='best_nhsdigital_match_' + str(match), right_on='NORMALIZED_NHSDigital_Supplier')\n",
    "    df_uniq = df_uniq.rename({'NHSDigital_Supplier': 'best_nhsdigital_match_' + str(match) + '_notnormalised'}, axis=1)\n",
    "    df_uniq = df_uniq.drop({'NORMALIZED_NHSDigital_Supplier'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d134acc-9eae-4a49-93f3-c2b4be5ea655",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniq = df_uniq[['SUPPLIER', 'contractsfinder_awardedToVcse', 'contractsfinder_region',\n",
    "                   'date', 'dept', 'PAYMENT_TOTAL_AMOUNT', 'ORG_COUNT',\n",
    "                   'NORMALIZED_SUPPLIER', 'PAYMENT_TOTAL_COUNT', 'NHSSpend_CompanyNumber',\n",
    "                   'NHSSpend_CharityRegNo', 'NHSSpend_CharitySubNo', 'deptcount',\n",
    "                   'verified_normalized_spine_name', 'verified_spine_uid',\n",
    "                   'verified_normalized_ch_name', 'verified_ch_uid',\n",
    "                   'verified_nhsdigital_name',\n",
    "                   'best_spine_match_1',\n",
    "                   'best_spine_match_1_score',\n",
    "                   'best_spine_match_1_notnormalised',\n",
    "                   'best_spine_match_2',\n",
    "                   'best_spine_match_2_score',\n",
    "                   'best_spine_match_2_notnormalised',\n",
    "                   'best_spine_match_3',\n",
    "                   'best_spine_match_3_score',\n",
    "                   'best_spine_match_3_notnormalised',\n",
    "                   'best_spine_match_4',\n",
    "                   'best_spine_match_4_score',\n",
    "                   'best_spine_match_4_notnormalised',\n",
    "                   'best_spine_match_5',\n",
    "                   'best_spine_match_5_score',\n",
    "                   'best_spine_match_5_notnormalised',\n",
    "                   'best_ch_match_1',\n",
    "                   'best_ch_match_1_score',\n",
    "                   'best_ch_match_1_notnormalised',\n",
    "                   'best_ch_match_2',\n",
    "                   'best_ch_match_2_score',\n",
    "                   'best_ch_match_2_notnormalised',\n",
    "                   'best_ch_match_3',\n",
    "                   'best_ch_match_3_score',\n",
    "                   'best_ch_match_3_notnormalised',\n",
    "                   'best_ch_match_4',\n",
    "                   'best_ch_match_4_score',\n",
    "                   'best_ch_match_4_notnormalised',\n",
    "                   'best_ch_match_5',\n",
    "                   'best_ch_match_5_score',\n",
    "                   'best_ch_match_5_notnormalised',\n",
    "                   'best_nhsdigital_match_1',\n",
    "                   'best_nhsdigital_match_1_score',\n",
    "                   'best_nhsdigital_match_1_notnormalised',\n",
    "                   'best_nhsdigital_match_2',\n",
    "                   'best_nhsdigital_match_2_score',\n",
    "                   'best_nhsdigital_match_2_notnormalised',\n",
    "                   'best_nhsdigital_match_3',\n",
    "                   'best_nhsdigital_match_3_score',\n",
    "                   'best_nhsdigital_match_3_notnormalised',\n",
    "                   'best_nhsdigital_match_4',\n",
    "                   'best_nhsdigital_match_4_score',\n",
    "                   'best_nhsdigital_match_4_notnormalised',\n",
    "                   'best_nhsdigital_match_5',\n",
    "                   'best_nhsdigital_match_5_score',\n",
    "                   'best_nhsdigital_match_5_notnormalised']]\n",
    "df_uniq.to_csv(os.path.join(os.getcwd(),\n",
    "                            '..',\n",
    "                            'raw_data',\n",
    "                            'merged_groupby_with_approximate_spine_and_ch_and_nhsdigital.csv'),\n",
    "               index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada5b91-5f05-4c3c-bb5c-a3f54fc9f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
