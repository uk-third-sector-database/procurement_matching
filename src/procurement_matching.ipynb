{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d30fd6-4457-43a9-81b4-ffdca0b8da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import html\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from matching_helpers import normaliser,\\\n",
    "                             parse_datetime,\\\n",
    "                             read_raw_data,\\\n",
    "                             prepare_nhsspend,\\\n",
    "                             prepare_contractsfinder,\\\n",
    "                             org_counter,\\\n",
    "                             strip_html,\\\n",
    "                             unique_agg,\\\n",
    "                             process_dates,\\\n",
    "                             make_matches\n",
    "\n",
    "tqdm.pandas()\n",
    "df_centgov = read_raw_data('centgov_data.csv', 'Contracts Finder')\n",
    "df_nhs = read_raw_data('nhsspend_data.csv', 'NHSSpend')\n",
    "df_contracts = read_raw_data('contractsfinder_data.csv', 'Contracts Finder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ecd37-3d4c-4cd9-9bd1-e617813f1aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_centgov = df_centgov[['data_source', 'amount', 'supplier', 'date', 'dept']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b677e21-64c7-40d4-bc6e-bfc1d8f8ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nhs = prepare_nhsspend(df_nhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283132ef-7ae8-49ec-81e4-7caac2dddc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contracts = prepare_contractsfinder(df_contracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73613a77-8eb9-4497-b570-b7780dfc0501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb = pd.concat([df_nhs, df_centgov, df_contracts], ignore_index=True)\n",
    "df_comb = df_comb.rename({'supplier': 'SUPPLIER'}, axis=1)\n",
    "df_comb['SUPPLIER'] = df_comb['SUPPLIER'].str.upper().str.strip()\n",
    "\n",
    "df_comb['SUPPLIER_NUMERIC'] = pd.to_numeric(df_comb['SUPPLIER'], errors='coerce')\n",
    "print(f'Dropping {len(df_comb[df_comb[\"SUPPLIER\"].isnull()])} rows of data because of numeric suppliers')\n",
    "df_comb = df_comb[df_comb['SUPPLIER'].notnull()]\n",
    "df_comb = df_comb[df_comb['SUPPLIER_NUMERIC'].isna()]\n",
    "df_comb = df_comb.drop(columns='SUPPLIER_NUMERIC')\n",
    "\n",
    "print(f'Dropping {len(df_comb[df_comb[\"SUPPLIER\"].isnull()])} rows of data because of NaN suppliers')\n",
    "df_comb = df_comb[df_comb['SUPPLIER'].notnull()]\n",
    "df_comb['SUPPLIER'] = df_comb['SUPPLIER'].progress_apply(strip_html)\n",
    "print(f'Dropping {len(df_comb[df_comb[\"SUPPLIER\"].isnull()])} rows of data after html parsing')\n",
    "df_comb = df_comb[df_comb['SUPPLIER'].notnull()]\n",
    "df_comb['date'] = df_comb['date'].astype(str).str.split('T').str[0]\n",
    "df_comb['date'] = pd.to_datetime(df_comb['date'],\n",
    "                                 format='mixed',\n",
    "                                 errors='coerce')\n",
    "df_comb['date'] = df_comb['date'].map(lambda x: x.strftime('%d-%m-%Y') if pd.notnull(x) else np.nan)\n",
    "print(f'Dropping {len(df_comb[df_comb[\"date\"].isnull()])} rows of data due to NaN dates')\n",
    "df_comb = df_comb[df_comb['date'].notnull()]\n",
    "print(f'Dropping {len(df_comb[df_comb[\"amount\"].isnull()])} rows of data due to NaN amounts')\n",
    "df_comb = df_comb[df_comb['amount'].notnull()]\n",
    "print(f'Dropping {len(df_comb[df_comb[\"dept\"].isnull()])} rows of data due to NaN depts')\n",
    "df_comb = df_comb[df_comb['dept'].notnull()]\n",
    "df_comb['NORMALIZED_SUPPLIER'] = df_comb['SUPPLIER'].progress_apply(normaliser)\n",
    "\n",
    "rows_to_drop = len(df_comb[\n",
    "    (df_comb[\"SUPPLIER\"].str.len() <= 3) |\n",
    "    (df_comb[\"NORMALIZED_SUPPLIER\"].str.len() <= 3)\n",
    "])\n",
    "\n",
    "# Print the message with the count of rows to be dropped\n",
    "print(f'Dropping {rows_to_drop} rows of data due to supplier str len<=3')\n",
    "\n",
    "df_comb = df_comb[\n",
    "    (df_comb[\"SUPPLIER\"].str.len() > 3) |\n",
    "    (df_comb[\"NORMALIZED_SUPPLIER\"].str.len() > 3)\n",
    "]\n",
    "\n",
    "df_comb[['SUPPLIER', 'ORG_COUNT']] = df_comb['SUPPLIER'].apply(lambda x: pd.Series(org_counter(x)))\n",
    "\n",
    "all_rows = len(df_comb)\n",
    "\n",
    "for supplier in [\"SUCCESSFUL SUPPL\",\n",
    "                 \"SEE ATTACH\",\n",
    "                 \"REFER ATTACH\",\n",
    "                 \"CONTRACT WAS AWARD\",\n",
    "                 \"AWARDED SUPPLIERS\",\n",
    "                 \"SUCCESSFUL SUPPLIER\",\n",
    "                 \"PLEASE SEE\",\n",
    "                 'NAMED IND',\n",
    "                 'REDACT',\n",
    "                 \"PLEASE REFER\"]:\n",
    "    df_comb = df_comb[~df_comb['SUPPLIER'].str.contains(supplier)]\n",
    "\n",
    "print(f'Number of rows dropped due to redacted: {len(df_comb)-all_rows}')\n",
    "\n",
    "print(f'Dropping {len(df_comb[df_comb[\"ORG_COUNT\"]!=1])} where org_count !=1')\n",
    "df_comb = df_comb[df_comb['ORG_COUNT']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f5ac99-8d9b-4acf-bde7-8a3f5b8029f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniq = df_comb.pivot_table(index=['SUPPLIER'],\n",
    "                              values=['date',\n",
    "                                      'contractsfinder_region',\n",
    "                                      'contractsfinder_awardedToVcse',\n",
    "                                      'dept'],\n",
    "                              aggfunc=unique_agg).reset_index()\n",
    "df_sum = df_comb.groupby('SUPPLIER')['amount'].sum().reset_index()\n",
    "df_counts = df_comb['SUPPLIER'].value_counts().reset_index()\n",
    "df_uniq = pd.merge(df_uniq,\n",
    "                   df_sum,\n",
    "                   how='left',\n",
    "                   left_on='SUPPLIER',\n",
    "                   right_on='SUPPLIER'\n",
    "                  )\n",
    "df_uniq[['SUPPLIER', 'ORG_COUNT']] = df_uniq['SUPPLIER'].progress_apply(lambda x: pd.Series(org_counter(x)))\n",
    "df_uniq['NORMALIZED_SUPPLIER'] = df_uniq['SUPPLIER'].progress_apply(normaliser)\n",
    "df_uniq = pd.merge(df_uniq,\n",
    "                   df_counts,\n",
    "                   how='left',\n",
    "                   left_on='SUPPLIER',\n",
    "                   right_on='SUPPLIER'\n",
    "                  )\n",
    "df_uniq.sort_values(by=['amount'],\n",
    "                    ascending=False)\n",
    "\n",
    "df_uniq1 = df_nhs[['supplier',\n",
    "                   'NHSSpend_CompanyName',\n",
    "                   'NHSSpend_CompanyNumber',\n",
    "                   'NHSSpend_CharityName',\n",
    "                   'NHSSpend_CharityRegNo',\n",
    "                   'NHSSpend_CharitySubNo',\n",
    "                   'NHSSpend_CharityNameNo',\n",
    "                   'NHSSpend_CharityName']].drop_duplicates()\n",
    "df_uniq = pd.merge(df_uniq,\n",
    "                   df_uniq1,\n",
    "                   how='left',\n",
    "                   left_on='SUPPLIER',\n",
    "                   right_on='supplier'\n",
    "                  )\n",
    "\n",
    "\n",
    "contractsfinder_region = df_sum = df_comb.groupby('SUPPLIER')['amount'].sum().reset_index()\n",
    "\n",
    "\n",
    "df_uniq = df_uniq.rename({'count': 'PAYMENT_TOTAL_COUNT',\n",
    "                          'amount': 'PAYMENT_TOTAL_AMOUNT'},\n",
    "                         axis=1)\n",
    "print(f'Dropping {len(df_uniq[df_uniq[\"ORG_COUNT\"]!=1])} org_count !=1')\n",
    "df_uniq = df_uniq[df_uniq['ORG_COUNT']==1]\n",
    "df_uniq = df_uniq.drop(columns='supplier')\n",
    "df_uniq['contractsfinder_awardedToVcse'] = df_uniq['contractsfinder_awardedToVcse'].apply(lambda x: \"True\" if True in x else \"False\")\n",
    "df_uniq['deptcount'] = df_uniq['dept'].astype(str).apply(lambda x: x.count(';') + 1)\n",
    "df_uniq['date'] = df_uniq['date'].astype(str).progress_apply(process_dates)\n",
    "df_uniq['SUPPLIER'] = df_uniq['SUPPLIER'].replace('\"', \"[DQ]\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdabed9-fe97-4c5f-9e92-c9162f45f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniq = df_uniq.drop('NHSSpend_CharityNameNo', axis=1)\n",
    "df_uniq = df_uniq.drop('NHSSpend_CharityName', axis=1)\n",
    "df_uniq = df_uniq.drop('NHSSpend_CompanyName', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b17853-120c-47c9-943f-1b99a104431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb = df_comb.drop('NHSSpend_CharityNameNo', axis=1)\n",
    "df_comb = df_comb.drop('NHSSpend_CharityName', axis=1)\n",
    "df_comb = df_comb.drop('NHSSpend_CompanyName', axis=1)\n",
    "df_comb = df_comb.drop('NHSSpend_audit_type', axis=1)\n",
    "df_comb = df_comb.drop('NHSSpend_CHnotes', axis=1)\n",
    "df_comb = df_comb.drop('NHSSpend_CCnotes', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a64f178-2c1c-40df-8995-b01a7a5b0826",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_uniq.columns)\n",
    "print(df_uniq.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77023526-ecc9-4670-8f66-fccc14694f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_comb.columns)\n",
    "print(df_comb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe67b913-79ff-4507-8e9e-f3f5ceda3e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniq = df_uniq.sort_values(by='PAYMENT_TOTAL_AMOUNT',\n",
    "                              ascending=False)\n",
    "df_uniq.to_csv(os.path.join(os.getcwd(),\n",
    "                            '..',\n",
    "                            'raw_data',\n",
    "                            'merged_groupby_singlesuppliers_raw.csv'),\n",
    "               index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ea287c-16eb-43b5-b515-2d8a3aaba02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb.to_csv(os.path.join(os.getcwd(),\n",
    "                            '..',\n",
    "                            'raw_data',\n",
    "                            'merged_singlesuppliers_raw.csv')\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1903878c-aa31-45fa-98b4-dc740ff7bde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We are then left with {len(df_uniq)} rows of unique \"single\" suppliers')\n",
    "print(f'We are then left with {len(df_comb)} rows of unique \"single\" payments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4af239-d625-41b6-9ada-1a350700e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch = pd.read_csv(os.path.join(\n",
    "    '..', 'registers', 'BasicCompanyDataAsOneFile-2024-08-01.csv'),\n",
    "                    usecols=['CompanyName', ' CompanyNumber']\n",
    "                )\n",
    "df_ch['NORMALIZED_CompanyName'] = df_ch['CompanyName'].progress_apply(normaliser)\n",
    "df_ch.to_csv(os.path.join('..', 'registers', 'ch_w_normalised.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee86c0e-29a5-4b9c-be10-f48c3e1314b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spine = pd.read_csv(os.path.join(\n",
    "    '..', 'registers', 'public_spine.spine.csv'),\n",
    "                       usecols=['uid', 'organisationname']\n",
    "                )\n",
    "df_spine['NORMALIZED_organisationname'] = df_spine['organisationname'].astype(str).progress_apply(normaliser)\n",
    "df_spine.to_csv(os.path.join('..', 'registers', 'spine_w_normalised.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d910d6bd-e61d-409a-a304-a5fd6dfdfc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniq['NORMALIZED_SUPPLIER'].tolist()[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7644451e-11a7-4044-934a-e8f347c8a6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spine_results = make_matches(df_uniq['NORMALIZED_SUPPLIER'].tolist(),\n",
    "                                df_spine.drop_duplicates(subset=['NORMALIZED_organisationname'],\n",
    "                                                         keep=False)['NORMALIZED_organisationname'].tolist(),\n",
    "                               'spine')\n",
    "df_spine_results.to_csv(os.path.join('..', 'matches', 'matches_to_spine.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d6ff19-4ea6-4893-835d-bb3fa9f07fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_results = make_matches(df_uniq['NORMALIZED_SUPPLIER'].tolist(),\n",
    "                             df_ch.drop_duplicates(subset=['NORMALIZED_CompanyName'],\n",
    "                                                   keep=False)['NORMALIZED_CompanyName'].tolist(),\n",
    "                             'ch'\n",
    "                            )\n",
    "df_ch_results.to_csv(os.path.join('..', 'matches', 'matches_to_ch.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
